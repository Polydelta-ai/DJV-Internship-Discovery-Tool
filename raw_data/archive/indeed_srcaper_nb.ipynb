{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from time import sleep\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_title(job):\n",
    "    \"\"\"\n",
    "    Takes a beautiful soup job object from a list of job_objects returned from:\n",
    "    jobs = soup.find_all('a','tapItem') \n",
    "    \"\"\"\n",
    "\n",
    "    spans = job.h2.find_all('span') \n",
    "    for i in range(len(spans)):\n",
    "        try:\n",
    "            title = spans[i]['title'].strip()\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    return title\n",
    "\n",
    "\n",
    "def get_job_link(job):\n",
    "    \"\"\"\n",
    "    Takes a beautiful soup job object from a list of job_objects returned from:\n",
    "    jobs = soup.find_all('a','tapItem') \n",
    "    \"\"\"\n",
    "\n",
    "    link1 = job.get('href')\n",
    "    link = 'https://www.indeed.com' + link1\n",
    "\n",
    "    return link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_record(job):\n",
    "    \n",
    "    job_title = get_job_title(job)\n",
    "    company_name = job.find('span', 'companyName').text\n",
    "    company_location = job.find('div', 'companyLocation').text\n",
    "    job_link = get_job_link(job)\n",
    "    salary = 'Unspecified'\n",
    "    job_type = 'Unspecified'\n",
    "\n",
    "    full_job_post = requests.get(job_link)\n",
    "    full_job_post = BeautifulSoup(full_job_post.text, 'html.parser')\n",
    "    full_job_description = full_job_post.find('div', {'id': \"jobDescriptionText\"}).text\n",
    "\n",
    "\n",
    "    # find the elements\n",
    "    job_details_section = full_job_post.find('div', {'id': \"jobDetailsSection\"})\n",
    "    job_details = job_details_section.find_all('div', 'jobsearch-JobDescriptionSection-sectionItem')\n",
    "\n",
    "    \n",
    "    # parse Salary and Job Type\n",
    "    for detail in job_details:\n",
    "        \n",
    "        if \"Salary\" in detail.text:\n",
    "            salary = detail.text.replace('Salary','')\n",
    "        \n",
    "        if \"Job Type\" in detail.text:\n",
    "            job_type = detail.text.replace('Job Type','')\n",
    "            list_of_job_types = [s for s in re.split(\"([A-Z][^A-Z]*)\", job_type) if s]\n",
    "            job_type = \", \".join(list_of_job_types)\n",
    "\n",
    "\n",
    "    # Get Extract Date\n",
    "    extract_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "    job_record = dict(\n",
    "        job_title = job_title,\n",
    "        company_name = company_name,\n",
    "        company_location = company_location,\n",
    "        job_link = job_link,\n",
    "        job_type = job_type,\n",
    "        salary = salary,\n",
    "        full_job_description = full_job_description,\n",
    "        extract_date = extract_date,\n",
    "    )\n",
    "    \n",
    "    return job_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_indeed_url(url):\n",
    "    records = []\n",
    "    start = 0\n",
    "\n",
    "    while True:\n",
    "        print(\"Requesting: \", url)\n",
    "        response = requests.get(url)\n",
    "\n",
    "        print(\"Repsonse Code: \", response.status_code)\n",
    "        print('\\n')\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        jobs = soup.find_all('a','tapItem')\n",
    "        for job in jobs:\n",
    "            record = get_record(job)\n",
    "            records.append(record)\n",
    "            print(\"Successfully added: \", record['job_title'])\n",
    "        try:\n",
    "            url = 'https://www.indeed.com' + soup.find('a', {'aria-label': 'Next'}).get('href')\n",
    "            start += 10\n",
    "            url = url[:-2] + str(start)\n",
    "            delay = randint(1, 10)\n",
    "            print('\\n')\n",
    "            print(f'Sleeping for {delay} seconds before starting the next request.')\n",
    "            sleep(delay)\n",
    "            print('\\n')\n",
    "\n",
    "        except AttributeError:\n",
    "            break\n",
    "    \n",
    "    print(\"Creating a pandas dataframe...\")\n",
    "    records_df = pd.DataFrame(records)\n",
    "\n",
    "    return records_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting:  https://www.indeed.com/jobs?q=park%20ranger&jt=internship&vjk=01dbabd30c208150\n",
      "Repsonse Code:  200\n",
      "\n",
      "\n",
      "Successfully added:  Wilderness Ranger Crew\n",
      "Successfully added:  Assistant Park Ranger\n",
      "Successfully added:  Park Interpreter\n",
      "Successfully added:  Seasonal Park Maintenance Associate\n",
      "Successfully added:  Seasonal Park Interpreter\n",
      "Successfully added:  Park Customer Service Seasonal Associate\n",
      "Successfully added:  Seasonal Park Ranger\n",
      "Creating a pandas dataframe...\n"
     ]
    }
   ],
   "source": [
    "test_two = scrape_indeed_url('https://www.indeed.com/jobs?q=park%20ranger&jt=internship&vjk=01dbabd30c208150')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_two.to_csv('park_ranger_internships.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indeed_scraper import scrape_indeed_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting:  https://www.indeed.com/jobs?as_and&as_phr&as_any=ecology%20ecological%20conservation%20conservancy%20wildlife%20fisheries%20fishery%20&as_not&as_ttl&as_cmp&jt=internship&st&salary&radius=25&l&fromage=any&limit=10&sort&psf=advsrch&from=advancedsearch&vjk=95e576aa42ce3a31\n",
      "Repsonse Code:  200\n",
      "\n",
      "\n",
      "Creating a pandas dataframe...\n"
     ]
    }
   ],
   "source": [
    "test_three = scrape_indeed_url('https://www.indeed.com/jobs?as_and&as_phr&as_any=ecology%20ecological%20conservation%20conservancy%20wildlife%20fisheries%20fishery%20&as_not&as_ttl&as_cmp&jt=internship&st&salary&radius=25&l&fromage=any&limit=10&sort&psf=advsrch&from=advancedsearch&vjk=95e576aa42ce3a31')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed Search Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeed_search_terms = ['conservation', 'ecology','husbandry','land management', 'biology',\n",
    "'natural resources', 'public water', 'park ranger', 'agriculture', 'forestry', 'botany',\n",
    "'environmental', 'species', 'fisheries','outdoors', 'wildlife', 'marine', 'aqua', 'horticulture']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Land Management- 266\n",
    "Public Water- 180\n",
    "Species- 152\n",
    "Conservation- 120\n",
    "Agriculture- 105\n",
    "Biology- 82\n",
    "Marine- 77\n",
    "Environmental- 70\n",
    "Ecology- 69\n",
    "Wildlife- 65\n",
    "Outdoors- 63\n",
    "Natural Resources- 53\n",
    "Horticulture- 42\n",
    "Fisheries- 26\n",
    "Husbandry- 20\n",
    "Botany- 19\n",
    "Forestry- 6\n",
    "Park Ranger- 5\n",
    "Aqua- 4"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3cddd25ca411fbee4e1de13c8254bc72d8d0336fa6eb8ce443b22e027565dc86"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
